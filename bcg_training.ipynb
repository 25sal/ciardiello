{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "example-training.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYrMcQUwk-Ar",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow._api.v2.compat.v1 as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "from scipy import signal\n",
    "\n",
    "from models import deeper_fcn as architecture\n",
    "from scipy.fft import fft, fftfreq\n",
    "import algorithms.heartrate as hr\n",
    "import algorithms.movement_detection as md\n",
    "import algorithms.common as cm\n",
    "import algorithms.segmenter as sg\n",
    "import utils\n",
    "from algorithms.FFT import FFT as FFT\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# tensorflow settings\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ],
   "metadata": {
    "id": "qAVJMlF6lDSl",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data\n",
    "# x_data_train, y_data_train, groups_train = ...\n",
    "# dummy:\n",
    "#data_folder = 'data'\n",
    "\n",
    "train_size = 774\n",
    "n_groups = 28\n",
    "data = np.genfromtxt('C:/Users/dario/Desktop/pr1/1000x400/rawprova1/raw_2022-03-14_bcg.csv', delimiter=';')\n",
    "# print the shape of the data\n",
    "#print(data.shape)\n",
    "\n",
    "movsign=md.detect_movements(data[:512],50)\n",
    "\n",
    "normalizzato=sg.renormalize_signal(data[:400],50)\n",
    "\n",
    "filtered=cm.filter_bandpass(normalizzato,50,2,10)\n",
    "filtered2=cm.filter_bandpass(data[:400],50,2,10)\n",
    "\n",
    "print(movsign.shape)\n",
    "plt.plot(normalizzato)\n",
    "plt.plot(filtered2, label='BCG Filtrato')\n",
    "plt.legend()\n",
    "'''\n",
    "plt.plot(movsign, label='movimento')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Tempo[s]\")\n",
    "plt.ylabel(\"Ampiezza\")\n",
    "plt.show()\n",
    "'''\n",
    "hearths=hr.get_heartrate_pipe(filtered)\n",
    "indicesijk=sg.find_ijk(filtered,50,[-1,-1,1])\n",
    "print(indicesijk)\n",
    "'''\n",
    "\n",
    "#FOURIER TRANSFORM (DFT)\n",
    "\n",
    "# Number of sample points\n",
    "N = 500\n",
    "# sample spacing\n",
    "T = 1.0 / 50.0\n",
    "x = np.linspace(0.0, N*T, N, endpoint=False)\n",
    "y = filtered\n",
    "yf = fft(y)\n",
    "xf = fftfreq(N, T)[:N//2]\n",
    "plt.stem(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Frequenza[Hz]\")\n",
    "plt.ylabel(\"Ampiezza\")\n",
    "plt.show()\n",
    "'''\n",
    "data = data[:len(data)-len(data)%400]\n",
    "# reshape the data to be 2D array with 400 columns and 5 rows   (400, 5)\n",
    "\n",
    "data = data.reshape( int(len(data)/400), 400)\n",
    "# print the shape of the data\n",
    "print(data.shape)\n",
    "\n",
    "x_data_train = np.expand_dims(data, axis=2)\n",
    "\n",
    "#y_train section\n",
    "data = np.genfromtxt('C:/Users/dario/Desktop/pr1/1000x400/gold/gold.csv', delimiter=',')\n",
    "print(len(data))\n",
    "y_data_train = np.mean(data.reshape(int(len(data)/16), 16), axis=1)\n",
    "y_data_train2=signal.resample(y_data_train,round(len(y_data_train)/2))\n",
    "\n",
    "\n",
    "# compute average each 8 elements in the array\n",
    "data = data[:len(data)-len(data)%16]\n",
    "y_data_train = np.mean(data.reshape(int(len(data)/16), 16), axis=1)\n",
    "y_data_train2=signal.resample(y_data_train,round(len(y_data_train)/2))\n",
    "y_data_train = y_data_train[:774]\n",
    "y= np.arange(0,400,1)\n",
    "\n",
    "xmax = y[np.argmax(y_data_train2)]\n",
    "ymax = y_data_train2.max()\n",
    "\n",
    "\n",
    "#xposmin = np.where(y_data_train2==min)\n",
    "#xmin = y[xposmin]\n",
    "print(xmax)\n",
    "print(ymax)\n",
    "#y_timedelta = [str(timedelta(seconds=int(s))) for s in y]\n",
    "#plt.plot(max,'o')\n",
    "#plt.plot(min,'o')\n",
    "\n",
    "#plt.plot(y_data_train[:400], label='gold')\n",
    "#plt.xticks(y_data_train2[:400],y_timedelta)\n",
    "plt.xlabel(\"Numero campioni \")\n",
    "plt.ylabel(\"Magnitudo\")\n",
    "#plt.plot(y_data_train2[:100], label='y_train2')\n",
    "#plt.plot(xmax,ymax,'X')\n",
    "#plt.plot(xmin,ymin,'X')\n",
    "print(\"zeros\",len(y_data_train) - np.count_nonzero(y_data_train))\n",
    "print(y_data_train.shape)\n",
    "# print first 2 rows of the data\n",
    "groups_train = np.sort(np.random.randint(n_groups, size=train_size))\n",
    "\n",
    "print(x_data_train.shape, y_data_train.shape, groups_train.shape)\n",
    "\n",
    "# print(x_data_train[0,:50])\n",
    "# plot x_data_train\n",
    "\n",
    "#plt.plot(x_data_train[:400], label='x_data_train')\n",
    "# plt.plot(y_data_train[:50], label='y_data_train')\n",
    "#plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "enlarge = 1\n",
    "model_params = dict(metrics=[\"mae\", \"mape\"], enlarge=enlarge)\n",
    "fit_params = dict(epochs=30, verbose=2)  # set epochs between 30 and 75\n",
    "\n",
    "modelname = (architecture.__name__ + \"-x{}\".format(enlarge))\n",
    "modelpath = os.path.join(\"output\", modelname)\n",
    "os.makedirs(os.path.join(modelpath, \"final\"), exist_ok=True)\n",
    "print(modelpath)\n",
    "\n",
    "# write model architecture to JSON file\n",
    "model = architecture.create(**model_params)\n",
    "with open(os.path.join(modelpath, \"model.json\"), \"w\") as fp:\n",
    "    fp.write(model.to_json())"
   ],
   "metadata": {
    "id": "31_KB7TjlQN5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\\models.deeper_fcn-x1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# single process for parallel training\n",
    "def process_split(xt, yt, i, fit_params):\n",
    "    # set allow_growth in subprocess\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf.keras.backend.set_session(tf.Session(config=config))\n",
    "    \n",
    "    csv_path = os.path.join(modelpath, \"logs-{:02d}.csv\".format(i))\n",
    "    weights_path = os.path.join(modelpath, \"weights-{:02d}.h5\".format(i))\n",
    "    fit_params.update(callbacks=[tf.keras.callbacks.CSVLogger(csv_path)])\n",
    "    \n",
    "    model = architecture.create(**model_params)\n",
    "    r = model.fit(xt, yt, **fit_params)\n",
    "    \n",
    "    model.save_weights(weights_path)\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    return r.history"
   ],
   "metadata": {
    "id": "gpibZvqglTjH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# split training data with LeaveOneGroupOut cross validation\n",
    "splitter = utils.get_group_splitter(n_groups, groups_train)"
   ],
   "metadata": {
    "id": "a8R5QRPKlalG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rs = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(process_split)(x_data_train[t_inds], y_data_train[t_inds],\n",
    "                           i, fit_params)\n",
    "    for i, (t_inds, v_inds) in enumerate(splitter)\n",
    ")"
   ],
   "metadata": {
    "id": "AaAtGPKRlcUX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  28 | elapsed:  7.2min remaining:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  28 out of  28 | elapsed:  7.8min finished\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = utils.get_model_from_json(modelpath, \"model.json\")\n",
    "\n",
    "# calculate MAPE and MAE for each left-out patient\n",
    "splitter = LeaveOneGroupOut().split(x_data_train, y_data_train, groups=groups_train)\n",
    "results = []\n",
    "for i, (t_inds, v_inds) in enumerate(splitter):\n",
    "    model.load_weights(os.path.join(modelpath, \"weights-{:02d}.h5\".format(i)))\n",
    "    y_pred = model.predict(x_data_train[v_inds])\n",
    "    y_true = y_data_train[v_inds]\n",
    "    results.append((hr.hr_mape(y_true, y_pred), hr.hr_mae(y_true, y_pred)))\n",
    "results = np.array(results)\n",
    "display(results)"
   ],
   "metadata": {
    "id": "R5AOZ_eElgHU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 569ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[32.90328934, 15.26580528],\n       [29.82754639, 15.69148838],\n       [34.90346695, 16.09085478],\n       [43.2275186 , 19.06615125],\n       [35.14385714, 16.22618612],\n       [45.56579489, 19.60356421],\n       [36.63916036, 15.99614742],\n       [36.56766887, 16.5581481 ],\n       [34.8638524 , 16.02547191],\n       [36.65380186, 15.74567611],\n       [36.40122055, 17.00071504],\n       [33.99871409, 15.78173564],\n       [40.43487234, 18.30919702],\n       [35.72014228, 16.73106031],\n       [44.9053473 , 20.22191915],\n       [41.59316341, 18.27210377],\n       [37.30987627, 16.89937582],\n       [39.32880385, 18.84948001],\n       [30.61743309, 15.54984255],\n       [36.90251601, 16.98108338],\n       [42.75683965, 18.55752985],\n       [56.42545361, 20.06551266],\n       [41.37010443, 17.78627777],\n       [36.37237064, 16.59767401],\n       [39.88016573, 16.98564293],\n       [40.16471091, 18.05527265],\n       [41.45487228, 19.83067557],\n       [37.83879318, 17.85752449]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 3s - loss: 963.9180 - mae: 24.5322 - mape: 59.3805 - 3s/epoch - 131ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 1s - loss: 474.5211 - mae: 18.1598 - mape: 42.4072 - 573ms/epoch - 23ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 1s - loss: 410.3180 - mae: 16.7055 - mape: 37.2297 - 626ms/epoch - 25ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 1s - loss: 393.6518 - mae: 17.0193 - mape: 40.1097 - 562ms/epoch - 22ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 1s - loss: 354.0025 - mae: 15.4270 - mape: 34.2894 - 592ms/epoch - 24ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 1s - loss: 352.4646 - mae: 15.9062 - mape: 35.7734 - 549ms/epoch - 22ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 1s - loss: 327.7592 - mae: 15.2600 - mape: 34.1663 - 547ms/epoch - 22ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 1s - loss: 319.8145 - mae: 14.9325 - mape: 33.3862 - 549ms/epoch - 22ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 1s - loss: 308.5597 - mae: 14.6626 - mape: 32.8503 - 589ms/epoch - 24ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 1s - loss: 304.6606 - mae: 14.3957 - mape: 32.1695 - 590ms/epoch - 24ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 1s - loss: 296.1560 - mae: 14.2772 - mape: 32.5196 - 584ms/epoch - 23ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 1s - loss: 301.4419 - mae: 14.1356 - mape: 31.2327 - 550ms/epoch - 22ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 1s - loss: 312.5645 - mae: 14.7484 - mape: 32.9897 - 567ms/epoch - 23ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 1s - loss: 304.2415 - mae: 14.5634 - mape: 32.8953 - 547ms/epoch - 22ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 1s - loss: 290.3898 - mae: 13.8468 - mape: 30.6080 - 547ms/epoch - 22ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 1s - loss: 289.0128 - mae: 13.9914 - mape: 31.4892 - 535ms/epoch - 21ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 1s - loss: 297.4624 - mae: 14.4100 - mape: 32.5482 - 545ms/epoch - 22ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 1s - loss: 285.7060 - mae: 14.0201 - mape: 31.8911 - 527ms/epoch - 21ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 1s - loss: 281.9785 - mae: 13.4777 - mape: 29.6326 - 546ms/epoch - 22ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 1s - loss: 276.7593 - mae: 13.5737 - mape: 30.7887 - 528ms/epoch - 21ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 1s - loss: 281.7013 - mae: 13.7539 - mape: 31.2744 - 584ms/epoch - 23ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 1s - loss: 285.6965 - mae: 13.6973 - mape: 30.5501 - 552ms/epoch - 22ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 1s - loss: 275.9613 - mae: 13.4153 - mape: 29.6771 - 541ms/epoch - 22ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 1s - loss: 282.7693 - mae: 13.9074 - mape: 31.6531 - 551ms/epoch - 22ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 1s - loss: 274.3407 - mae: 13.4260 - mape: 29.8971 - 534ms/epoch - 21ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 1s - loss: 270.7065 - mae: 13.3096 - mape: 29.6958 - 812ms/epoch - 32ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 1s - loss: 270.7464 - mae: 13.2911 - mape: 29.8847 - 638ms/epoch - 26ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 1s - loss: 274.5677 - mae: 13.3810 - mape: 29.9625 - 536ms/epoch - 21ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 1s - loss: 263.0768 - mae: 13.0192 - mape: 28.7601 - 540ms/epoch - 22ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 1s - loss: 261.6108 - mae: 12.8418 - mape: 28.2993 - 574ms/epoch - 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# train one model on entire training set\n",
    "\n",
    "model = architecture.create(**model_params)\n",
    "r = model.fit(x_data_train, y_data_train, **fit_params)\n",
    "model.save_weights(os.path.join(modelpath, \"final\", \"weights-00.h5\"))\n",
    "tf.keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}